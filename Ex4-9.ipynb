{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCISE 4.9\n",
    "### Write a computer program to perform a quadratic discriminant\n",
    "### analysis by fitting a separate Gaussian model per class. Try it out on the\n",
    "### vowel data, and compute the misclassification error for the test data.\n",
    "\n",
    "### Setup \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import multivariate_normal as GaussianRV\n",
    "from numpy.random import uniform\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=11\n",
      "N=10\n",
      "   y    x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8    x.9   x.10\n",
      "0  1 -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529 -0.874 -0.814\n",
      "1  2 -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510 -0.621 -0.488\n",
      "2  3 -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676 -0.809 -0.049\n",
      "3  4 -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235 -0.091 -0.795\n",
      "4  5 -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150  0.277 -0.396\n",
      "y         int64\n",
      "x.1     float64\n",
      "x.2     float64\n",
      "x.3     float64\n",
      "x.4     float64\n",
      "x.5     float64\n",
      "x.6     float64\n",
      "x.7     float64\n",
      "x.8     float64\n",
      "x.9     float64\n",
      "x.10    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Read training dataset\n",
    "training_set=pd.read_csv(\"vowel/training_set.csv\").drop(columns='row.names')\n",
    "N=len(training_set.drop(columns=['y']).keys())\n",
    "K=len(training_set['y'].unique())\n",
    "print(\"K={}\".format(K))\n",
    "print(\"N={}\".format(N))\n",
    "print(training_set.head()) \n",
    "print(training_set.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y       x.1       x.2       x.3       x.4       x.5       x.6       x.7  \\\n",
      "0  1 -3.359563  0.062937 -0.294062  1.203333  0.387479  1.221896  0.096375   \n",
      "1  2 -2.708875  0.490604 -0.580229  0.813500  0.201938  1.063479 -0.190917   \n",
      "2  3 -2.440250  0.774875 -0.798396  0.808667  0.042458  0.569250 -0.280062   \n",
      "3  4 -2.226604  1.525833 -0.874437  0.422146 -0.371313  0.248354 -0.018958   \n",
      "4  5 -2.756313  2.275958 -0.465729  0.225312 -1.036792  0.389792  0.236417   \n",
      "\n",
      "        x.8       x.9      x.10  \n",
      "0  0.037104 -0.624354 -0.161625  \n",
      "1  0.373813 -0.515958  0.080604  \n",
      "2  0.204958 -0.478271  0.181875  \n",
      "3  0.107146 -0.326271 -0.053750  \n",
      "4  0.424625 -0.200708 -0.280708  \n",
      "              x.1        x.2        x.3        x.4        x.5        x.6  \\\n",
      "y                                                                          \n",
      "1 x.1  112.545234  53.446980  81.308825  63.701099  30.394740  20.853743   \n",
      "  x.2   53.446980  35.598352  38.573517  25.281134  16.001868  21.101397   \n",
      "  x.3   81.308825  38.573517  62.654489  48.982371  19.656055  19.687082   \n",
      "  x.4   63.701099  25.281134  48.982371  65.118069  15.496474  14.349921   \n",
      "  x.5   30.394740  16.001868  19.656055  15.496474  18.825609   1.164708   \n",
      "\n",
      "             x.7        x.8        x.9       x.10  \n",
      "y                                                  \n",
      "1 x.1  23.335388 -32.243605  30.045269 -56.354115  \n",
      "  x.2  10.825190 -18.644248  15.882985 -23.452362  \n",
      "  x.3  23.259420 -22.085338  23.203021 -38.487045  \n",
      "  x.4  37.608729 -11.234993  22.139601 -24.113826  \n",
      "  x.5  -1.826800  -2.300848   3.660797 -16.064627  \n",
      "   y           det\n",
      "0  1  1.462637e-09\n",
      "1  2  4.310302e-11\n",
      "2  3  3.017185e-12\n",
      "3  4  2.279559e-12\n",
      "4  5  3.768920e-12\n",
      "    y  counts    N      pi_k\n",
      "0  11      48  528  0.090909\n",
      "1  10      48  528  0.090909\n",
      "2   9      48  528  0.090909\n",
      "3   8      48  528  0.090909\n",
      "4   7      48  528  0.090909\n"
     ]
    }
   ],
   "source": [
    "### Fit separate Gaussians for each class \n",
    "# calculate class means\n",
    "means=training_set.copy().groupby(by='y').mean().reset_index()\n",
    "# calculate class cov matrix\n",
    "sigma=training_set.copy().groupby(by='y').cov()\n",
    "sigma_inverse=sigma.copy()\n",
    "# calculate inverse and determinant of class covariance matrices \n",
    "detDB=pd.DataFrame(columns=['y','det'])\n",
    "for cindx in np.arange(1,K+1):\n",
    "    # slice out the covariance matrix\n",
    "    cov_matrix=sigma.copy().loc[(cindx,slice(None))]\n",
    "    # claculate determinant and inverse\n",
    "    det=np.linalg.det(cov_matrix.to_numpy())\n",
    "    inv=np.linalg.inv(cov_matrix.to_numpy())\n",
    "    # save in DBs \n",
    "    detDB=pd.concat([detDB,pd.DataFrame({'y': [cindx], 'det': [det]})],sort=False)\n",
    "    sigma_inverse.loc[(cindx,slice(None)\n",
    "                      )]=pd.DataFrame(inv, columns=sigma.keys(), index=pd.MultiIndex.from_tuples([(cindx,el) for el in cov_matrix.index]))\n",
    "detDB=detDB.sort_values(by='y').reset_index(drop=True)\n",
    "# calculate prior probabs  \n",
    "pik=training_set.copy()['y'].value_counts().reset_index().rename(columns={'y':'counts','index':'y'})\n",
    "pik['N']=pik.assign(fakekey=1).groupby(by='fakekey')['counts'].sum().iloc[0]\n",
    "pik['pi_k']=pik['counts'].div(pik['N'])\n",
    "print(means.head()) ; print(sigma_inverse.head()); print(detDB.head()); print(pik.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y    x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8    x.9   x.10\n",
      "0  1 -1.149 -0.904 -1.988  0.739 -0.060  1.206  0.864  1.196 -0.300 -0.467\n",
      "1  2 -2.613 -0.092 -0.540  0.484  0.389  1.741  0.198  0.257 -0.375 -0.604\n",
      "2  3 -2.505  0.632 -0.593  0.304  0.496  0.824 -0.162  0.181 -0.363 -0.764\n",
      "3  4 -1.768  1.769 -1.142 -0.739 -0.086  0.120 -0.230  0.217 -0.009 -0.279\n",
      "4  5 -2.671  3.155 -0.514  0.133 -0.964  0.234 -0.071  1.192  0.254 -0.471\n"
     ]
    }
   ],
   "source": [
    "### Read test dataset\n",
    "test_set=pd.read_csv(\"vowel/test_set.csv\").drop(columns=['row.names'])\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                         QDA_values    QDA_max  \\\n",
      "0        0  [-7.471428644483783, -55.015652157020334, -156...  -7.471429   \n",
      "1        1  [-10.4700844680682, 7.149851287630272, -59.985...   7.149851   \n",
      "2        2  [-48.066767548451686, -16.47612971350034, -11....  -6.497370   \n",
      "3        3  [-106.81221146127704, -63.65862491514442, -53.... -20.880017   \n",
      "4        4  [-77.21366988667799, -61.13696059035083, -194....   3.800325   \n",
      "..     ...                                                ...        ...   \n",
      "457    457  [-92.18859261158795, -94.1502463233152, -230.1...  -8.055364   \n",
      "458    458  [-140.9736649277744, -192.92575137235838, -330... -24.297209   \n",
      "459    459  [-55.747741647369686, -91.65076105540727, -111...   0.022585   \n",
      "460    460  [-91.0476790872223, -85.24229389915574, -144.1... -25.048163   \n",
      "461    461  [-57.88439925180882, -37.39790185079726, -83.5...  -5.056748   \n",
      "\n",
      "     max_position  yhat  \n",
      "0               0     1  \n",
      "1               1     2  \n",
      "2               5     6  \n",
      "3               3     4  \n",
      "4               6     7  \n",
      "..            ...   ...  \n",
      "457             4     5  \n",
      "458             8     9  \n",
      "459             8     9  \n",
      "460             8     9  \n",
      "461             6     7  \n",
      "\n",
      "[462 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "### Calculate QDA predictions \n",
    "def QDF(z):\n",
    "    # calculate quadratic discriminant functions \n",
    "    qdas=[]\n",
    "    for cindx in np.arange(1,K+1):\n",
    "        m=means.loc[means.y==cindx].drop(columns=['y']).to_numpy().flatten()\n",
    "        s=sigma_inverse.copy().loc[(cindx,slice(None))].to_numpy()\n",
    "        d=float(detDB.loc[detDB.y==cindx,'det'])\n",
    "        p=float(pik.loc[pik.y==cindx,'pi_k'])\n",
    "        qt=-0.5*np.log(d)-0.5*np.matmul((z-m).T,np.matmul(s,z-m))+np.log(p)\n",
    "        qdas.append(qt)\n",
    "    return qdas\n",
    "\n",
    "predictions=test_set.copy().drop(columns=['y']).groupby(by=None,axis=0,level=0).apply(lambda z: QDF(z.to_numpy().flatten()))\n",
    "predictions=predictions.reset_index().rename(columns={0:'QDA_values'})\n",
    "predictions['QDA_max']=predictions['QDA_values'].apply(lambda z: np.amax(z))\n",
    "predictions['max_position']=predictions['QDA_values'].apply(lambda z: int(np.where(z==np.amax(z))[0]))\n",
    "predictions['yhat']=predictions['max_position'].apply(lambda z: 1+z)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error = 0.5281385281385281\n",
      "accuracy = 0.47186147186147187\n"
     ]
    }
   ],
   "source": [
    "### Calculate misclassification error\n",
    "summary=test_set.reset_index().merge(predictions[['index','yhat']],on='index',how='left')\n",
    "summary['misclassification_error']=(summary['y']==summary['yhat']\n",
    "                                          ).apply(lambda z: 0 if z==True else 1)\n",
    "err=int(summary['misclassification_error'].sum())\n",
    "print(\"misclassification error = {}\".format(err/len(summary)))\n",
    "print(\"accuracy = {}\".format(1-err/len(summary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy=0.47186147186147187\n"
     ]
    }
   ],
   "source": [
    "### SAFETY CHECK \n",
    "### SKLEARN AUTOMATIC ALGO \n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "\n",
    "X, y=training_set.drop(columns=['y']).to_numpy(), training_set['y'].to_numpy()\n",
    "Xtest, ytest=test_set.drop(columns=['y']).to_numpy(), test_set['y'].to_numpy()\n",
    "\n",
    "model=QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "model.fit(X,y)\n",
    "print(\"model accuracy={}\".format(model.score(Xtest,ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check class means \n",
    "print(np.array_equal(model.means_,means.drop(columns=['y']).to_numpy()))\n",
    "# check class covariance matrices \n",
    "print(all([ np.array_equal(np.round(model.covariance_[indx],12),\n",
    "                       np.round(sigma.loc[(1+indx,slice(None))].to_numpy(),12)) for indx in np.arange(0,K)]))\n",
    "# check priors \n",
    "print(np.array_equal(model.priors_,pik.sort_values(by='y')['pi_k'].to_numpy()))\n",
    "# check predictions \n",
    "print(np.array_equal(model.predict(Xtest),predictions['yhat'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy=0.487012987012987\n"
     ]
    }
   ],
   "source": [
    "### Compare with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lgrmodel=LogisticRegression(penalty='none',multi_class='multinomial',solver='lbfgs',max_iter=1000)\n",
    "lgrmodel.fit(X,y)\n",
    "print(\"model accuracy={}\".format(lgrmodel.score(Xtest,ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6  \\\n",
      "0  -6.872759 -0.855551 -0.633501  1.904107  0.652272  3.198679  1.118163   \n",
      "1  -5.683781 -0.024880 -1.146121  1.168588  0.426158  2.592411  0.092777   \n",
      "2  -5.001466  0.253328 -1.886939  1.056531 -0.141017  1.184715 -0.447197   \n",
      "3  -4.348150  1.378681 -1.883907  0.589635 -1.154367  0.503278 -0.123243   \n",
      "4  -5.332996  2.562241 -0.806624  0.352881 -2.459004  1.372592  0.739184   \n",
      "5  -5.166597  1.835202 -0.978124  0.510367 -1.636403  1.425474  0.669613   \n",
      "6  -6.265679  2.835330 -0.489416  0.518781 -2.071922  1.210426  0.594241   \n",
      "7  -7.644116  3.935167 -0.602332  0.625773 -2.043123  1.730187  0.988577   \n",
      "8  -7.607942  2.581761 -0.678955  0.552538 -0.746478  2.809279  0.692778   \n",
      "9  -8.421559  3.031111 -0.627774  1.014298  0.026100  2.869414  1.168527   \n",
      "10 -6.135309  1.183112 -1.094978  0.395773 -1.034160  1.930528  0.016576   \n",
      "\n",
      "           7         8         9  fakekey  \n",
      "0   1.894807 -0.415325 -0.344197        1  \n",
      "1   2.294953 -0.194093  0.344292        1  \n",
      "2   1.728091 -0.352560  0.404401        1  \n",
      "3   1.240241 -0.135613  0.008304        1  \n",
      "4   2.006691  0.183048 -0.274755        1  \n",
      "5   1.752095  0.222249  0.320284        1  \n",
      "6   3.243511  0.705436  0.038077        1  \n",
      "7   3.957422  1.369994  0.507681        1  \n",
      "8   3.692378  0.873847  0.189796        1  \n",
      "9   3.467331  1.396338 -0.111967        1  \n",
      "10  2.502032  0.146318 -0.237221        1  \n"
     ]
    }
   ],
   "source": [
    "### Reduced-rank LDA \n",
    "\n",
    "### Step 1. \n",
    "# calculate matrix of class centroids \n",
    "M=means.copy().drop(columns=['y']).to_numpy()\n",
    "# calculate within-class covariance \n",
    "features_no=len(training_set)\n",
    "W=np.zeros((N,N))\n",
    "for l in np.arange(1,K+1):\n",
    "    # slice out the covariance matrix\n",
    "    rcovmat=sigma.copy().loc[(l,slice(None))].to_numpy()*(int(pik.loc[pik.y==l,'counts'])-1)\n",
    "    W=np.add(W,rcovmat)\n",
    "W=W/(features_no-K)\n",
    "\n",
    "### Step 2. \n",
    "# eigendecomposition of W \n",
    "d, U=np.linalg.eig(W)\n",
    "z=[1./np.sqrt(z) for z in d]\n",
    "Wsqr=np.matmul(U,np.matmul(np.diag(z),U.T))\n",
    "Mstar=np.matmul(M,Wsqr)\n",
    "\n",
    "### Step 3. \n",
    "# Bstar=pd.DataFrame(Mstar).assign(fakekey=1)\n",
    "# Bstar=Bstar.groupby(by='fakekey').cov().reset_index(drop=True).to_numpy()\n",
    "# d, Vstar=np.linalg.eig(Bstar)\n",
    "# print(Bstar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
